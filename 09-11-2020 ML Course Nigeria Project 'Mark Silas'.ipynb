{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "In this project, the aim is to build a model for predicting churn. Churn is the percentage of customers that stopped using your company's product or service during a certain time frame. Thus, in the given dataset, the label or target variable will be `Churn` column.\n",
    "\n",
    "## Steps\n",
    "- Read the `churn.csv` file and describe it.\n",
    "- Make at least 4 different analysis on Exploratory Data Analysis section.\n",
    "- Pre-process the dataset to get ready for ML application. (Check missing data and handle them, do we need to do scaling or feature extraction etc.)\n",
    "- Define appropriate evaluation metric for our case (classification).\n",
    "- Train and evaluate Logistic Regression, Decision Trees and one other appropriate algorithm which you can choose from scikit-learn library.\n",
    "- Is there any overfitting and underfitting? Interpret your results and try to overcome if there is any problem in a new section.\n",
    "- Create confusion metrics for each algorithm and display Accuracy, Recall, Precision and F1-Score values.\n",
    "- Analyse and compare results of 3 algorithms.\n",
    "- Select best performing model based on evaluation metric you chose on test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARK SILAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libray for data analysis and visualisation\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv\n",
    "data = pd.read_csv(\"churn.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for shape of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing columns of data\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the summary descriptive statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking data information\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cheking for total of missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for duplicate values\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value counts for churn column\n",
    "data['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the target variable(Churn)\n",
    "ax = sns.countplot(x=\"Churn\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Visualising AccountWeeks column\n",
    "sns.displot(data=data, x=\"AccountWeeks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value count for Contract renewal\n",
    "data['ContractRenewal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value counts for DataPlan column\n",
    "data['DataPlan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising DataUSage column\n",
    "sns.displot(data=data, x=\"DataUsage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising CustServCalls column\n",
    "sns.displot(data=data, x=\"CustServCalls\", kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value counts for DayMins\n",
    "pd.qcut(data['DayMins'],5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value counts for DayCalls\n",
    "pd.qcut(data['DayCalls'],5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value count for MonthlyCharge\n",
    "pd.qcut(data['MonthlyCharge'],5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising OverageFee column\n",
    "sns.displot(data=data, x=\"OverageFee\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising RoamMins column\n",
    "sns.displot(data=data, x=\"RoamMins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation for Churn w.r.t AccountWeeks\n",
    "sns.displot(data=data, x=\"AccountWeeks\", hue=\"Churn\", multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the correlation between features\n",
    "sns.heatmap(data.corr(),annot=True,linewidths=0.2) \n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(20,12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Z-score to find unusual data point values such as outliers\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "z = np.abs(stats.zscore(data))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for outliers(outliers always have z-scores  above 3)\n",
    "outliers = list(set(np.where(z > 3)[0]))\n",
    "len(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Outliers\n",
    "Data = data[(z < 3).all(axis=1)]\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a threadpool to handle accuracy score and classification report\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def model_testing(md):\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        executor.submit(md.fit, X_train, y_train)\n",
    "    print(\"Training Accuracy: \", md.score(X_train, y_train), '\\n')\n",
    "    print(\"Testing Accuracy: \", md.score(X_test, y_test), '\\n')\n",
    "    print(classification_report(y_test, md.predict(X_test)))\n",
    "    return md.predict(data.drop(columns=['Churn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Various Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Setting your columns into attributes and label\n",
    "X = Data[['AccountWeeks', 'ContractRenewal', 'DataPlan', 'DataUsage', 'CustServCalls', 'DayMins', 'DayCalls', 'MonthlyCharge', 'OverageFee', 'RoamMins']]\n",
    "y = Data['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing training and testsing, standadisation and pipeline module \n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#Splitting data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the object of the models model \n",
    "log = LogisticRegression(solver=\"liblinear\", C=10, random_state=42, n_jobs=-1).fit(X_train, y_train)\n",
    "dct= tree.DecisionTreeClassifier(max_depth=4 , random_state=42).fit(X_train, y_train)\n",
    "svc = SVC(C=10, probability=True).fit(X_train, y_train)\n",
    "rfc = RandomForestClassifier(n_estimators=200).fit(X_train, y_train)\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "gbc = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "gsc = GridSearchCV(estimator = log, param_grid  = {\"C\": [0.1,0.01,0.001,10,1]}, cv= 5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of training label\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trainer(X_train, y_train,):\n",
    "    classifiers = [log, dct, svc, rfc, knn, gbc]\n",
    "    for classifier in classifiers:\n",
    "        metrics = model_testing(classifier)\n",
    "        print(metrics)\n",
    "        print(classifier)\n",
    "\n",
    "trainer(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistcis Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the probabilities of training attributes\n",
    "log.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "confusion_matrix(y_train, log.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visulaising confusion matrix\n",
    "cm = confusion_matrix(y_train, log.predict(X_train))\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area under the roc curve measures the performance of the model. ROC curve above 0.50 shows good performace.\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred_prop = log.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr_log, tpr_log, _ = roc_curve(y_test, y_pred_prop)\n",
    "roc_auc_log = auc(fpr_log, tpr_log)\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(fpr_log, tpr_log, color='darkorange',\n",
    "         label='ROC curve (area = %0.2f)' % roc_auc_log)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate',fontsize=18,labelpad =10)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Receiver Operating Characteristic',fontsize=22).set_position([.5, 1.02])\n",
    "plt.legend(loc=\"lower right\",fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print best parameter after tuning \n",
    "gsc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print best score after tunning \n",
    "gsc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score of test data after tunning\n",
    "gsc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, dct.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_train, dct.predict(X_train))\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.heatmap(c_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, svc.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix = confusion_matrix(y_train, svc.predict(X_train))\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.heatmap(con_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, rfc.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix = confusion_matrix(y_train, rfc.predict(X_train))\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.heatmap(con_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, knn.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix = confusion_matrix(y_train, knn.predict(X_train))\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.heatmap(con_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, gbc.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix = confusion_matrix(y_train, gbc.predict(X_train))\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.heatmap(con_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be no overfitting or underfitting as train data performed well in all model\n",
    "\n",
    "The best performing model is Random Forest with:\n",
    "\n",
    "Training Accuracy: 1.0\n",
    "\n",
    "Testing Accuracy: 0.952054794520548\n",
    "\n",
    "Hypertuning the model would improve it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
